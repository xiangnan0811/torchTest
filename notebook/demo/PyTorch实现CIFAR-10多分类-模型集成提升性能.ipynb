{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 导入需要的模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义超参数\n",
    "BATCHSIZE=100\n",
    "DOWNLOAD_MNIST=False\n",
    "EPOCHES=20\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义相关模型结构，这三个网络结构比较接近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=16,kernel_size=5,stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=36,kernel_size=3,stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1296,128)\n",
    "        self.fc2 = nn.Linear(128,10)      \n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool1(F.relu(self.conv1(x)))\n",
    "        x=self.pool2(F.relu(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        x=x.view(-1,36*6*6)\n",
    "        x=F.relu(self.fc2(F.relu(self.fc1(x))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 36, 5)\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.aap=nn.AdaptiveAvgPool2d(1)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(36, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        #x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.aap(x)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                            nn.BatchNorm2d(x),\n",
    "                            nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../data', train=True, download=False, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../../data', train=False, download=False, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net1 = CNNNet()\n",
    "net2=Net()\n",
    "net3=LeNet()\n",
    "net4 = VGG('VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0集成模型的正确率47.22\n",
      "模型0的正确率为：32.09\n",
      "模型1的正确率为：40.6\n",
      "模型2的正确率为：44.85\n",
      "模型3的正确率为：46.94\n",
      "epoch:1集成模型的正确率57.18\n",
      "模型0的正确率为：35.75\n",
      "模型1的正确率为：46.93\n",
      "模型2的正确率为：50.66\n",
      "模型3的正确率为：63.88\n",
      "epoch:2集成模型的正确率58.8\n",
      "模型0的正确率为：42.49\n",
      "模型1的正确率为：47.22\n",
      "模型2的正确率为：52.67\n",
      "模型3的正确率为：65.86\n",
      "epoch:3集成模型的正确率62.45\n",
      "模型0的正确率为：43.76\n",
      "模型1的正确率为：52.14\n",
      "模型2的正确率为：55.37\n",
      "模型3的正确率为：73.85\n",
      "epoch:4集成模型的正确率65.75\n",
      "模型0的正确率为：45.36\n",
      "模型1的正确率为：52.43\n",
      "模型2的正确率为：56.13\n",
      "模型3的正确率为：76.41\n",
      "epoch:5集成模型的正确率66.55\n",
      "模型0的正确率为：45.56\n",
      "模型1的正确率为：53.34\n",
      "模型2的正确率为：57.43\n",
      "模型3的正确率为：79.31\n",
      "epoch:6集成模型的正确率67.98\n",
      "模型0的正确率为：45.93\n",
      "模型1的正确率为：53.2\n",
      "模型2的正确率为：59.1\n",
      "模型3的正确率为：81.99\n",
      "epoch:7集成模型的正确率69.54\n",
      "模型0的正确率为：45.86\n",
      "模型1的正确率为：55.79\n",
      "模型2的正确率为：60.07\n",
      "模型3的正确率为：82.21\n",
      "epoch:8集成模型的正确率68.67\n",
      "模型0的正确率为：45.55\n",
      "模型1的正确率为：55.69\n",
      "模型2的正确率为：59.98\n",
      "模型3的正确率为：81.79\n",
      "epoch:9集成模型的正确率68.9\n",
      "模型0的正确率为：46.16\n",
      "模型1的正确率为：55.66\n",
      "模型2的正确率为：60.02\n",
      "模型3的正确率为：84.16\n",
      "epoch:10集成模型的正确率70.81\n",
      "模型0的正确率为：47.4\n",
      "模型1的正确率为：57.03\n",
      "模型2的正确率为：62.24\n",
      "模型3的正确率为：84.52\n",
      "epoch:11集成模型的正确率73.22\n",
      "模型0的正确率为：47.38\n",
      "模型1的正确率为：57.68\n",
      "模型2的正确率为：62.18\n",
      "模型3的正确率为：85.91\n",
      "epoch:12集成模型的正确率72.03\n",
      "模型0的正确率为：47.51\n",
      "模型1的正确率为：58.02\n",
      "模型2的正确率为：63.12\n",
      "模型3的正确率为：86.93\n",
      "epoch:13集成模型的正确率71.64\n",
      "模型0的正确率为：46.9\n",
      "模型1的正确率为：58.0\n",
      "模型2的正确率为：63.1\n",
      "模型3的正确率为：87.23\n",
      "epoch:14集成模型的正确率73.01\n",
      "模型0的正确率为：46.88\n",
      "模型1的正确率为：58.6\n",
      "模型2的正确率为：64.15\n",
      "模型3的正确率为：87.9\n",
      "epoch:15集成模型的正确率73.88\n",
      "模型0的正确率为：47.69\n",
      "模型1的正确率为：60.46\n",
      "模型2的正确率为：64.18\n",
      "模型3的正确率为：87.12\n",
      "epoch:16集成模型的正确率74.15\n",
      "模型0的正确率为：48.06\n",
      "模型1的正确率为：59.79\n",
      "模型2的正确率为：64.73\n",
      "模型3的正确率为：88.34\n",
      "epoch:17集成模型的正确率74.04\n",
      "模型0的正确率为：48.43\n",
      "模型1的正确率为：60.66\n",
      "模型2的正确率为：65.39\n",
      "模型3的正确率为：88.07\n",
      "epoch:18集成模型的正确率75.74\n",
      "模型0的正确率为：48.26\n",
      "模型1的正确率为：61.31\n",
      "模型2的正确率为：65.49\n",
      "模型3的正确率为：88.59\n",
      "epoch:19集成模型的正确率74.82\n",
      "模型0的正确率为：48.13\n",
      "模型1的正确率为：60.81\n",
      "模型2的正确率为：65.9\n",
      "模型3的正确率为：87.9\n"
     ]
    }
   ],
   "source": [
    "#把3个网络模型放在一个列表里\n",
    "mlps=[net1.to(device), net2.to(device), net3.to(device), net4.to(device)]\n",
    "optimizer=torch.optim.Adam([{\"params\":mlp.parameters()} for mlp in mlps],lr=LR)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "\n",
    "for ep in range(EPOCHES):\n",
    "    for img,label in trainloader:\n",
    "        img,label=img.to(device), label.to(device)\n",
    "        optimizer.zero_grad()  # 10个网络清除梯度\n",
    "        for mlp in mlps:\n",
    "            mlp.train()\n",
    "            out=mlp(img)\n",
    "            loss=loss_function(out,label)\n",
    "            loss.backward()  # 网络们获得梯度\n",
    "        optimizer.step()\n",
    "\n",
    "    pre=[]\n",
    "    vote_correct=0\n",
    "    mlps_correct=[0 for i in range(len(mlps))]\n",
    "    for img,label in testloader:\n",
    "        img,label=img.to(device), label.to(device)\n",
    "        for i, mlp in  enumerate(mlps):\n",
    "            mlp.eval()\n",
    "            out=mlp(img)\n",
    "\n",
    "            _,prediction=torch.max(out,1) #按行取最大值\n",
    "            pre_num=prediction.cpu().numpy()\n",
    "            mlps_correct[i]+=(pre_num==label.cpu().numpy()).sum()\n",
    "\n",
    "            pre.append(pre_num)\n",
    "        arr=np.array(pre)\n",
    "        pre.clear()\n",
    "        result=[Counter(arr[:,i]).most_common(1)[0][0] for i in range(BATCHSIZE)]\n",
    "        vote_correct+=(result == label.cpu().numpy()).sum()\n",
    "    print(\"epoch:\" + str(ep)+\"集成模型的正确率\"+str(vote_correct/len(testloader)))\n",
    "\n",
    "    for idx, coreect in enumerate( mlps_correct):\n",
    "        print(\"模型\"+str(idx)+\"的正确率为：\"+str(coreect/len(testloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8da56f91c5d255bdcbac18e3f64f42e2d11710e9cce859fc127084dddda9c283"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
